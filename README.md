<div align="center">
    <h1 style="display: inline-flex; align-items: center;">
        <img src="img/static/icon.png" alt="icon" style="width: 32px; height: 32px; margin-right: 8px;">
        Awesome Latent Space
    </h1>
</div>

<p align="center">
    <a href="https://github.com/sindresorhus/awesome"><img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" alt="Awesome list badge"></a>
    <a href="https://github.com/YU-deep/Awesome-Latent-Space/stargazers"><img src="https://img.shields.io/github/stars/YU-deep/Awesome-Latent-Space?style=social" alt="GitHub stars"></a>
    <a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="MIT License"></a>
    <a href="CONTRIBUTING.md"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" alt="PRs welcome"></a>
    <a href="img/static/wechat_group.jpg"><img src="https://img.shields.io/badge/Group-WeChat-07c160?logo=wechat&logoColor=white" alt="WeChat Group"></a>
</p>

This repository manually collects works in **latent space**, which will be continuously updated.


## üìñ News
**[2025/11/30]** We release the initial version!

## üåü Overview
- [üìñ News](#-news)
- [üåü Overview](#-overview)
- [ü§ù Contributing](#-contributing)
- [üî• Methods](#-methods)
  - [Large-Language-Model](#large-language-model)
  - [Vision-Language-Model](#vision-language-model)
  - [Multi-Agent-System](#multi-agent-system)
  - [Vision-Language-Action-Model](#vision-language-action-model)
  - [World-Model](#world-model)


## ü§ù Contributing
We warmly welcome contributions of excellent resources you find via **pull request**. Please follow the instruction in **CONTRIBUTING.md** if you want to make one.
Additionally, if you want to have any other issue, please add our wechat group.








## üî• Methods
### Large-Language-Model
| Date     | Paper Title                                                                                                                                                                                                    | Introduction                                                        | Code                                                                                                                      |
|----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|
| 2024/11  | [Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding](https://arxiv.org/abs/2411.04282)                                                                           | <img width="700" alt="image" src="img/llm/2411_latro.png">          | [Github](https://github.com/SalesforceAIResearch/LaTRO)                                                                   |
| 2024/12  | ![COLM'25](https://img.shields.io/badge/COLM'25-f1b800) <br/> [Training Large Language Models to Reason in a Continuous Latent Space](https://arxiv.org/abs/2412.06769)                                        | <img width="700" alt="image" src="img/llm/2412_coconut.png">        | [Github](https://github.com/facebookresearch/coconut)                                                                     |
| 2024/12  | ![ICML'25](https://img.shields.io/badge/ICML'25-f1b800) <br/> [Deliberation in Latent Space via Differentiable Cache Augmentation](https://arxiv.org/abs/2412.17747)                                           | <img width="700" alt="image" src="img/llm/2412_deliberation.png">   | -                                                                                                                         |
| 2025/02  | ![ICML'25](https://img.shields.io/badge/ICML'25-f1b800) <br/> [Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning](https://arxiv.org/abs/2502.03275)                          | <img width="700" alt="image" src="img/llm/2502_token.png">          | -                                                                                                                         |
| 2025/02  | ![ACL'25](https://img.shields.io/badge/ACL'25-f1b800) <br/> [SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs](https://arxiv.org/abs/2502.12134)                                               | <img width="700" alt="image" src="img/llm/2502_soft_cot.png">       | [Github](https://github.com/xuyige/SoftCoT)                                                                               |
| 2025/02  | ![ICLR'25](https://img.shields.io/badge/ICLR'25-f1b800) <br/> [Reasoning with Latent Thoughts: On the Power of Looped Transformers](https://arxiv.org/abs/2502.17416)                                          | <img width="700" alt="image" src="img/llm/2502_reasoning.png">      | -                                                                                                                         |
| 2025/02  | ![EMNLP'25](https://img.shields.io/badge/EMNLP'25-f1b800) <br/>  [CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation](https://arxiv.org/abs/2502.21074)                            | <img width="700" alt="image" src="img/llm/2502_codi.png">           | [Github](https://github.com/zhenyi4/codi)                                                                                 |
| 2025/03  | ![ICLR'25](https://img.shields.io/badge/ICLR'25-f1b800) <br/> [Reasoning to Learn from Latent Thoughts](https://arxiv.org/abs/2503.18866?)                                                                     | <img width="700" alt="image" src="img/llm/2503_bolt.png">           | [Github](https://github.com/ryoungj/BoLT)                                                                                 |
| 2025/03  | [Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation](https://arxiv.org/abs/2503.22675)                                                                                | <img width="700" alt="image" src="img/llm/2503_rearec.png">         | -                                                                                                                         |
| 2025/04  | [Efficient Pretraining Length Scaling](https://arxiv.org/abs/2504.14992)                                                                                                                                       | <img width="700" alt="image" src="img/llm/2504_phd.png">            | -                                                                                                                         |
| 2025/05  | [SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.11484)                                                                                                          | <img width="700" alt="image" src="img/llm/2505_soft_cot_plus.png">  | [Github](https://github.com/xuyige/SoftCoT)                                                                               |
| 2025/05  | ![NeurIPS'25](https://img.shields.io/badge/NeurIPS'25-f1b800) <br/> [Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought](https://arxiv.org/abs/2505.12514)                   | <img width="700" alt="image" src="img/llm/2505_reasoning.png">      | [Github](https://github.com/Ber666/reasoning-by-superposition)                                                            |
| 2025/05  | [Enhancing Latent Computation in Transformers with Latent Tokens](https://arxiv.org/abs/2505.12629)                                                                                                            | <img width="700" alt="image" src="img/llm/2505_enhancing.png">      | -                                                                                                                         |                                                                               
| 2025/05  | [Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space](https://arxiv.org/abs/2505.13308)                                                                                   | <img width="700" alt="image" src="img/llm/2505_latent_seek.png">    | [Github](https://github.com/bigai-nlco/LatentSeekhttps://github.com/bigai-nlco/LatentSeek)                                |         
| 2025/05  | ![NeurIPS'25](https://img.shields.io/badge/NeurIPS'25-f1b800) <br/> [Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains](https://arxiv.org/abs/2505.16552)                         | <img width="700" alt="image" src="img/llm/2505_colar.png">          | [Github](https://github.com/xiaomi-research/colar)                                                                        |
| 2025/05  | [LARES: Latent Reasoning for Sequential Recommendation](https://arxiv.org/abs/2505.16865)                                                                                                                      | <img width="700" alt="image" src="img/llm/2505_lares.png">          | -                                                                                                                         |
| 2025/05  | [Hybrid Latent Reasoning via Reinforcement Learning](https://arxiv.org/abs/2505.18454)                                                                                                                         | <img width="700" alt="image" src="img/llm/2505_hrpo.png">           | [Github](https://github.com/thu-nics/C2C)                                                                                 |
| 2025/05  | [System-1.5 Reasoning: Traversal in Language and Latent Spaces with Dynamic Shortcuts](https://arxiv.org/abs/2505.18962)                                                                                       | <img width="700" alt="image" src="img/llm/2505_system_15.png">      | -                                                                                                                         |
| 2025/05  | ![ICML'25](https://img.shields.io/badge/ICML'25-f1b800) <br/> [Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration](https://arxiv.org/abs/2505.24688) | <img width="700" alt="image" src="img/llm/2505_soft.png">           | [Github](https://github.com/alickzhu/Soft-Reasoning)                                                                      |
| 2025/06  | [Efficient Post-Training Refinement of Latent Reasoning in Large Language Models](https://arxiv.org/abs/2506.08552)                                                                                            | <img width="700" alt="image" src="img/llm/2506_efficient.png">      | [Github](https://github.com/anord-wang/Lateng-Reasoning)                                                                  |
| 2025/07  | ![EMNLP'25](https://img.shields.io/badge/EMNLP'25-f1b800) <br/> [Latent Inter-User Difference Modeling for LLM Personalization](https://arxiv.org/abs/2507.20849)                                              | <img width="700" alt="image" src="img/llm/2507_dep.png">            | [Github](https://github.com/SnowCharmQ/DEP)                                                                               |
| 2025/08  | [Bridging Search and Recommendation through Latent Cross Reasoning](https://www.arxiv.org/abs/2508.04152)                                                                                                      | <img width="700" alt="image" src="img/llm/2508_lcr_ser.png">        | -                                                                                                                         |
| 2025/09  | [Decoding in Latent Spaces for Efficient Inference in LLM-based Recommendation](https://arxiv.org/abs/2509.11524)                                                                                              | <img width="700" alt="image" src="img/llm/2509_l2d.png">            | -                                                                                                                         |
| 2025/09  | [LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning](https://arxiv.org/abs/2509.12875)                                                                    | <img width="700" alt="image" src="img/llm/2509_lta_thinker.png">    | [Github](https://github.com/wangjiaqi886/LTA-Thinker)                                                                     |
| 2025/09  | [SIM-CoT: Supervised Implicit Chain-of-Thought](https://arxiv.org/abs/2509.20317)                                                                                                                              | <img width="700" alt="image" src="img/llm/2509_sim_cot.png">        | [Github](https://github.com/InternLM/SIM-CoT)                                                                             |
| 2025/09  | [Pretraining LLM with Latent Thoughts in Continuous Space](https://arxiv.org/abs/2509.23184)                                                                                                                   | <img width="700" alt="image" src="img/llm/2509_ponderlm2.png">      | [Github](https://github.com/LUMIA-Group/PonderLM-2)                                                                       |
| 2025/09  | [MemGen: Weaving Generative Latent Memory for Self-Evolving Agents](https://arxiv.org/abs/2509.24704)                                                                                                          | <img width="700" alt="image" src="img/llm/2509_memgen.png">         | [Github](https://github.com/KANABOON1/MemGen)                                                                             |
| 2025/09  | [LatentEvolve: Self-Evolving Test-Time Scaling in Latent Space](https://arxiv.org/abs/2509.24771)                                                                                                              | <img width="700" alt="image" src="img/llm/2509_latent_evolve.png">  | [Github](https://github.com/jins7/LatentEvolve)                                                                           |
| 2025/09  | [MARCOS: Deep Thinking by Markov Chain of Continuous Thoughts](https://arxiv.org/abs/2509.25020)                                                                                                               | <img width="700" alt="image" src="img/llm/2509_marcos.png">         | -                                                                                                                         |
| 2025/09  | [Latent Thinking Optimization: Your Latent Reasoning Language Model Secretly Encodes Reward Signals in Its Latent Thoughts](https://arxiv.org/abs/2509.26314)                                                  | <img width="700" alt="image" src="img/llm/2509_huginn.png">         | -                                                                                                                         |
| 2025/10  | [KaVa: Latent Reasoning via Compressed KV-Cache Distillation](https://arxiv.org/abs/2510.02312)                                                                                                                | <img width="700" alt="image" src="img/llm/2510_kava.png">           | -                                                                                                                         |
| 2025/10  | [Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought Policy Optimization](https://arxiv.org/abs/2510.04182)                                                                                | <img width="700" alt="image" src="img/llm/2510_ltpo.png">           | [Github](https://github.com/ltpo2025/LTPO)                                                                                |
| 2025/10  | [LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning](https://arxiv.org/abs/2510.04573)                                                                                                                   | <img width="700" alt="image" src="img/llm/2510_ladir.png">          | [Github](https://github.com/mk322/LaDiR)                                                                                  | 
| 2025/10  | [Encode, Think, Decode: Scaling test-time reasoning with recursive latent thoughts](https://arxiv.org/abs/2510.07358)                                                                                          | <img width="700" alt="image" src="img/llm/2510_etd.png">            | -                                                                                                                         |
| 2025/10  | [Parallel Test-Time Scaling for Latent Reasoning Models](https://arxiv.org/abs/2510.07745)                                                                                                                     | <img width="700" alt="image" src="img/llm/2510_agn.png">            | [Github](https://github.com/YRYangang/LatentTTS)                                                                          |
| 2025/10  | [Unlocking Out-of-Distribution Generalization in Transformers via Recursive Latent Space Reasoning](https://arxiv.org/abs/2510.14095)                                                                          | <img width="700" alt="image" src="img/llm/2510_ood.png">            | [Github](https://github.com/Awni00/algorithmic-generalization-transformer-architectures)                                  |
| 2025/10  | [Latent Reasoning in LLMs as a Vocabulary-Space Superposition](https://arxiv.org/abs/2510.15522)                                                                                                               | <img width="700" alt="image" src="img/llm/2510_latent_sft.png">     | [Github](https://github.com/DJC-GO-SOLO/Latent-SFT)                                                                       |
| 2025/10  | [SemCoT: Accelerating Chain-of-Thought Reasoning through Semantically-Aligned Implicit Tokens](https://arxiv.org/abs/2510.24940)                                                                               | <img width="700" alt="image" src="img/llm/2510_sem_cot.png">        | [Github](https://github.com/YinhanHe123/SemCoT)                                                                           |
| 2025/10  | [Scaling Latent Reasoning via Looped Language Models](https://arxiv.org/abs/2510.25741)                                                                                                                        | <img width="700" alt="image" src="img/llm/2510_ouro.png">           | -                                                                                                                         |
| 2025/11  | [SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization](https://arxiv.org/abs/2511.06411)                                               | <img width="700" alt="image" src="img/llm/2511_soft_cot.png">       | [Github](https://github.com/zz1358m/SofT-GRPO-master)                                                                     |
| 2025/11  | [Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models](https://arxiv.org/abs/2511.08577)                                                                                            | <img width="700" alt="image" src="img/llm/2511_tah.png">            | [Github](https://github.com/apple/ml-clara)                                                                               | 
| 2025/11  | [SpiralThinker: Latent Reasoning through an Iterative Process with Text-Latent Interleaving](https://arxiv.org/abs/2511.08983)                                                                                 | <img width="700" alt="image" src="img/llm/2511_spiral_thinker.png"> | -                                                                                                                         |
| 2025/11  | [Improving Latent Reasoning in LLMs via Soft Concept Mixing](https://arxiv.org/abs/2511.16885)                                                                                                                 | <img width="700" alt="image" src="img/llm/2511_scm.png">            | -                                                                                                                         |
| 2025/11  | [CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning](https://arxiv.org/abs/2511.18659)                                                                                                  | <img width="700" alt="image" src="img/llm/2511_clara.png">          | [Github](https://github.com/apple/ml-clara)                                                                               | 
| 2025/11  | [Learning When to Stop: Adaptive Latent Reasoning via Reinforcement Learning](https://arxiv.org/abs/2511.21581)                                                                                                | <img width="700" alt="image" src="img/llm/2511_learning.png">       | [Github](https://github.com/apning/adaptive-latent-reasoning)                                                             |
| 2025/12  | [Lightweight Latent Reasoning for Narrative Tasks](https://arxiv.org/abs/2512.02240)                                                                                                                           | <img width="700" alt="image" src="img/llm/2512_lite_reason.png">    | -                                                                                                                         |
| 2025/12  | [ReLaX: Reasoning with Latent Exploration for Large Reasoning Models](https://arxiv.org/abs/2512.07558)                                                                                                        | <img width="700" alt="image" src="img/llm/2512_relax.png">          | -                                                                                                                         |
| 2025/12  | [Reinforcement Learning for Latent-Space Thinking in LLMs](https://arxiv.org/abs/2512.11816)                                                                                                                   | <img width="700" alt="image" src="img/llm/2512_reinforcement.png">  | [Github](https://github.com/enesozeren/latent-space-thinking-model)                                                       |
| 2025/12  | [Reasoning Palette: Modulating Reasoning via Latent Contextualization for Controllable Exploration for (V)LMs](https://arxiv.org/abs/2512.17206)                                                               | <img width="700" alt="image" src="img/llm/2512_repa.png">           | -                                                                                                                         |
| 2025/12  | [JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation](https://arxiv.org/abs/2512.19171)                                                                                                           | <img width="700" alt="image" src="img/llm/2512_jepa_reasoner.png">  | -                                                                                                                         |
| 2025/12  | [Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space](https://arxiv.org/abs/2512.24617v1)                                                                                             | <img width="700" alt="image" src="img/llm/2512_dlcm.png">           | -                                                                                                                         |
| 2026/01  | [Parallel Latent Reasoning for Sequential Recommendation](https://arxiv.org/abs/2601.03153)                                                                                                                    | <img width="700" alt="image" src="img/llm/2601_plr.png">            | -                                                                                                                         |
| 2026/01  | [FlashMem: Distilling Intrinsic Latent Memory via Computation Reuse](https://arxiv.org/abs/2601.05505)                                                                                                         | <img width="700" alt="image" src="img/llm/2601_flashmem.png">       | -                                                                                                                         |
| 2026/01  | [IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck](https://arxiv.org/abs/2601.05870)                                                                                                   | <img width="700" alt="image" src="img/llm/2601_i2b_lpo.png">        | [Github](https://github.com/denghuilin-cyber/IIB-LPO)                                                                     |
| 2026/01  | [Silence the Judge: Reinforcement Learning with Self-Verifier via Latent Geometric Clustering](https://arxiv.org/abs/2601.08427)                                                                               | <img width="700" alt="image" src="img/llm/2601_latent_grpo.png">    | -                                                                                                                         |
| 2026/01  | [Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models](https://arxiv.org/abs/2601.08058)                                                                                    | <img width="700" alt="image" src="img/llm/2601_reasoning.png">      | -                                                                                                                         |
| 2026/01  | [RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering](https://arxiv.org/abs/2601.09269)                                                                                              | <img width="700" alt="image" src="img/llm/2601_riser.png">          | [Github](https://github.com/gooogleshanghai/RISER-Orchestrating-Latent-Reasoning-Skills-for-Adaptive-Activation-Steering) |
| 2026/01  | [GeoSteer: Faithful Chain-of-Thought Steering via Latent Manifold Gradients](https://arxiv.org/abs/2601.10229)                                                                                                 | <img width="700" alt="image" src="img/llm/2601_geosteer.png">       | -                                                                                                                         |


### Vision-Language-Model
| Date     | Paper Title                                                                                                                                                                | Introduction                                                     | Code                                                          |
|----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|---------------------------------------------------------------|
| 2024/12  | ![CVPR'25](https://img.shields.io/badge/CVPR'25-f1b800) <br/> [Perception Tokens Enhance Visual Reasoning in Multimodal Language Models](https://arxiv.org/abs/2412.03548) | <img width="700" alt="image" src="img/vlm/2412_aurora.png">      | [Github](https://github.com/mahtabbigverdi/Aurora-perception) |
| 2025/01  | [Efficient Reasoning with Hidden Thinking](https://arxiv.org/abs/2501.19201)                                                                                               | <img width="700" alt="image" src="img/vlm/2501_heima.png">       | [Github](https://github.com/shawnricecake/Heima)              |
| 2025/05  | [Towards General Continuous Memory for Vision-Language Models](https://arxiv.org/abs/2505.17670)                                                                           | <img width="700" alt="image" src="img/vlm/2505_comem.png">       | [Github](https://github.com/WenyiWU0111/CoMEM/tree/main)      |
| 2025/06  | [Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens](https://arxiv.org/abs/2506.17218)                                                         | <img width="700" alt="image" src="img/vlm/2506_mirage.png">      | [Github](https://github.com/UMass-Embodied-AGI/Mirage)        |
| 2025/08  | [Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models](https://arxiv.org/abs/2508.12587)                                            | <img width="700" alt="image" src="img/vlm/2508_mcout.png">       | -                                                             | 
| 2025/09  | [Latent Visual reasoning](https://arxiv.org/abs/2509.24251)                                                                                                                | <img width="700" alt="image" src="img/vlm/2509_lvr.png">         | -                                                             |
| 2025/10  | [Auto-scaling Continuous Memory for GUI Agent](https://arxiv.org/abs/2510.09038)                                                                                           | <img width="700" alt="image" src="img/vlm/2510_auto.png">        | [Github](https://github.com/WenyiWU0111/CoMEM-Agent)          |
| 2025/10  | [Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space](https://arxiv.org/abs/2510.12603)                                                               | <img width="700" alt="image" src="img/vlm/2510_ivt_lr.png">      | [Github](https://github.com/FYYDCC/IVT-LR)                    |
| 2025/10  | [Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views](https://arxiv.org/abs/2510.18632)                                                     | <img width="700" alt="image" src="img/vlm/2510_think.png">       | [Github](https://github.com/zhangquanchen/3DThinker)          |
| 2025/10  | [Latent Chain-of-Thought for Visual Reasoning](https://arxiv.org/abs/2510.23925)                                                                                           | <img width="700" alt="image" src="img/vlm/2510_lacot.png">       | [Github](https://github.com/heliossun/LaCoT)                  |
| 2025/10  | [Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs](https://arxiv.org/abs/2510.24514)                                                    | <img width="700" alt="image" src="img/vlm/2510_sketchpad.png">   | [Github](https://github.com/hwanyu112/Latent-Sketchpad)       |
| 2025/11  | [CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space Reasoning](https://arxiv.org/abs/2511.02360)                                                         | <img width="700" alt="image" src="img/vlm/2511_cocova.png">      | -                                                             |
| 2025/11  | [VisMem: Latent Vision Memory Unlocks Potential of Vision-Language Model](https://www.arxiv.org/abs/2511.11007)                                                            | <img width="700" alt="image" src="img/vlm/2511_vismem.png">      | [Github](https://github.com/YU-deep/VisMem)                   |
| 2025/11  | [Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens](https://arxiv.org/abs/2511.19418)                                           | <img width="700" alt="image" src="img/vlm/2511_covt.png">        | [Github](https://github.com/Wakals/CoVT)                      |
| 2025/11  | [Monet: Reasoning in Latent Visual Space Beyond Image and Language](https://arxiv.org/abs/2511.21395)                                                                      | <img width="700" alt="image" src="img/vlm/2511_monet.png">       | [Github](https://github.com/NOVAglow646/)                     |
| 2025/12  | [Interleaved Latent Visual Reasoning with Selective Perceptual Modeling](https://arxiv.org/abs/2512.05665v1)                                                               | <img width="700" alt="image" src="img/vlm/2512_ilvr.png">        | [Github](https://github.com/XD111ds/ILVR)                     |
| 2025/12  | [Mull-Tokens: Modality-Agnostic Latent Thinking](https://arxiv.org/abs/2512.10941)                                                                                         | <img width="700" alt="image" src="img/vlm/2512_mull.png">        | -                                                             |
| 2025/12  | [Reasoning Within the Mind: Dynamic Multimodal Interleaving in Latent Space](https://arxiv.org/abs/2512.12623)                                                             | <img width="700" alt="image" src="img/vlm/2512_mind.png">        | [Github](https://github.com/eric-ai-lab/DMLR)                 |
| 2025/12  | [Sketch-in-Latents: Eliciting Unified Reasoning in MLLMs](https://arxiv.org/abs/2512.16584)                                                                                | <img width="700" alt="image" src="img/vlm/2512_skila.png">       | [Github](https://github.com/TungChintao/SkiLa)                |
| 2025/12  | [Latent Implicit Visual Reasoning](https://arxiv.org/abs/2512.21218)                                                                                                       | <img width="700" alt="image" src="img/vlm/2512_livr.png">        | -                                                             |
| 2026/01  | [Forest Before Trees: Latent Superposition for Efficient Visual Reasoning](https://arxiv.org/abs/2601.06803)                                                               | <img width="700" alt="image" src="img/vlm/2601_laser.png">       | [Github](https://github.com/ybb6/laser)                       |
| 2026/01  | [Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions](https://arxiv.org/abs/2601.07516)                                                     | <img width="700" alt="image" src="img/vlm/2601_controlling.png"> | -                                                             |
| 2026/01  | [LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning](https://arxiv.org/abs/2601.10129)                                                                       | <img width="700" alt="image" src="img/vlm/2601_lavit.png">       | [Github](https://github.com/Svardfox/LaViT)                   |
| 2026/01  | [Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning](https://www.arxiv.org/abs/2601.14750)                                                                       | <img width="700" alt="image" src="img/vlm/2601_rot.png">       | [Github](https://github.com/TencentBAC/RoT)                   |


### Multi-Agent-System
| Date     | Paper Title                                                                                                                                               | Introduction                                                     | Code                                             |
|----------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|--------------------------------------------------|
| 2025/10  | [Cache-to-Cache: Direct Semantic Communication Between Large Language Model](https://arxiv.org/abs/2510.03215)                                            | <img width="700" alt="image" src="img/mas/2510_c2c.png">         | [Github](https://github.com/thu-nics/C2C)        |
| 2025/10  | ![NeurIPS'25](https://img.shields.io/badge/NeurIPS'25-f1b800) <br/> [Thought Communication in Multiagent Collaboration](https://arxiv.org/abs/2510.20733) | <img width="700" alt="image" src="img/mas/2510_thoughtcomm.png"> | -                                                |
| 2025/11  | [Enabling Agents to Communicate Entirely in Latent Space](https://arxiv.org/abs/2511.09149)                                                               | <img width="700" alt="image" src="img/mas/2511_interlat.png">    | -                                                |
| 2025/11  | [Latent Collaboration in Multi-Agent Systems](https://arxiv.org/abs/2511.20639)                                                                           | <img width="700" alt="image" src="img/mas/2511_latent_mas.png">  | [Github](https://github.com/Gen-Verse/LatentMAS) |
| 2026/01  | [Latent Space Communication via K-V Cache Alignment](https://www.arxiv.org/abs/2601.06123)                                                                | <img width="700" alt="image" src="img/mas/2601_latent.png">      | -                                                |


### Vision-Language-Action-Model
| Date     | Paper Title                                                                                                                                    | Introduction                                                         | Code                                                      |
|----------|------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------|-----------------------------------------------------------|
| 2025/05  | [UniVLA: Learning to Act Anywhere with Task-centric Latent Actions](https://arxiv.org/abs/2505.06111)                                          | <img width="700" alt="image" src="img/vla/2505_univla.png">          | [Github](https://github.com/OpenDriveLab/UniVLA)          |
| 2025/07  | [ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning](https://arxiv.org/abs/2507.16815)                           | <img width="700" alt="image" src="img/vla/2507_thinkact.png">        | [Github](https://jasper0314-huang.github.io/thinkact-vla) |
| 2025/07  | [Villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models](https://arxiv.org/abs/2507.23682)                                 | <img width="700" alt="image" src="img/vla/2507_villax.png">          | [Github](https://github.com/microsoft/villa-x)            |
| 2025/09  | [Latent Action Pretraining Through World Modeling](https://arxiv.org/abs/2509.18428)                                                           | <img width="700" alt="image" src="img/vla/2509_lawm.png">            | -                                                         |
| 2025/11  | [LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models](https://www.arxiv.org/pdf/2511.23034)                          | <img width="700" alt="image" src="img/vla/2511_latbot.png">          | -                                                         | 
| 2025/12  | [Latent Chain-of-Thought World Modeling for End-to-End Autonomous Driving](https://arxiv.org/abs/2512.10226)                                   | <img width="700" alt="image" src="img/vla/2512_lc_drive.png">        | -                                                         |
| 2025/12  | [WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control](https://arxiv.org/abs/2512.11047)                          | <img width="700" alt="image" src="img/vla/2512_whole_body_vla.png">  | [Github](https://github.com/OpenDriveLab/WholebodyVLA)    |
| 2025/12  | [Motus: A Unified Latent Action World Model](https://arxiv.org/pdf/2512.13030)                                                                 | <img width="700" alt="image" src="img/vla/2512_motus.png">           | [Github](https://github.com/thu-ml/Motus)                 |
| 2025/12  | [LoLA: Long Horizon Latent Action Learning for General Robot Manipulation](https://arxiv.org/abs/2512.20166v1)                                 | <img width="700" alt="image" src="img/vla/2512_lola.png">            | -                                                         |
| 2026/01  | [CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos](https://arxiv.org/abs/2601.04061v1) | <img width="700" alt="image" src="img/vla/2601_clap.png">            | -                                                         |
| 2026/01  | [LaST0: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model](https://arxiv.org/abs/2601.05248)                    | <img width="700" alt="image" src="img/vla/2601_last.png">            | -                                                         |
| 2026/01  | [LatentVLA: Efficient Vision-Language Models for Autonomous Driving via Latent Action Prediction](https://arxiv.org/abs/2601.05611)            | <img width="700" alt="image" src="img/vla/2601_latent_vla.png">      | -                                                         |
| 2026/01  | [Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning](https://arxiv.org/abs/2601.09708)                 | <img width="700" alt="image" src="img/vla/2601_fast_thinkact.png">   | -                                                         |

### World-Model
| Date     | Paper Title                                                                                                              | Introduction                                                  | Code |
|----------|--------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------|------|
| 2025/06  | [Video World Models with Long-term Spatial Memory](https://arxiv.org/abs/2506.05284)                                     | <img width="700" alt="image" src="img/wm/2506_ltsm.png">      | -    |
| 2025/06  | [V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning](https://arxiv.org/abs/2506.09985) | <img width="700" alt="image" src="img/wm/2506_vjepa2.png">    | -    |
| 2025/09  | [Latent Action Pretraining Through World Modeling](https://arxiv.org/abs/2509.18428)                                     | <img width="700" alt="image" src="img/wm/2509_lawm.png">      | -    |
| 2025/12  | [RELIC: Interactive Video World Model with Long-Horizon Memory](https://arxiv.org/abs/2512.04040)                        | <img width="700" alt="image" src="img/wm/2512_relic.png">     | -    |
| 2025/12  | [Latent Chain-of-Thought World Modeling for End-to-End Autonomous Driving](https://arxiv.org/abs/2512.10226)             | <img width="700" alt="image" src="img/wm/2512_lc_drive.png">  | -    |
| 2025/12  | [World Models Can Leverage Human Videos for Dexterous Manipulation](https://arxiv.org/abs/2512.13644)                    | <img width="700" alt="image" src="img/wm/2512_hvdm.png">      | -    |
| 2026/01  | [Learning Latent Action World Models In The Wild](https://arxiv.org/abs/2601.05230)                                      | <img width="700" alt="image" src="img/wm/2601_learning.png">  | -    |